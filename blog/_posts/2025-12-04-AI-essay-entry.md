---
layout: post
title: 2025 Burning Glass Essay Submission
date: 2025-12-04
jumbotron: 2025 Burning Glass Essay Submission
regular_date: December 4, 2025
summary:  My entry for the 2025 Burning Glass Institute AI Essay Competition.
---

<figure style="text-align:center;">
<img src="https://s3.amazonaws.com/NARAprodstorage/lz/stillpix/255-grc/Batch004/255-GRC-1985-C-01346.JPG" 
     alt="A flow chart that will guide a lecture or discussion about artificial intelligence (identifier 514785)" 
     title="A colored flow chart of Artificial Intelligence"
     style="width:70%; height:auto;" />
     <figcaption style="font-style: italic; margin-top: 10px;">
          This is a flow chart for talking to your loved ones about artificial intelligence. If you don't do it, who will? (NAID: 514785)
     </figcaption>
</figure>

---
### Jump to Section
{:.no_toc}
* TOC
{:toc}
--- 

**The following was my entry for the 2025 Binding Hook AI Essay Competition. I did not place, but I enjoyed researching and writing it.**

### An AI World Still Needs Humans
Artificial intelligence (AI) will not replace us. Generative AI and large language models (LLM) will automate many tasks now performed by humans, but they will not replace us. As [one Estonian official observed](https://www.ria.ee/sites/default/files/documents/2024-02/Cyber-security-in-Estonia-2024.pdf), “AI can free people from drudgery, letting them focus on aspects that still require human intelligence.” AI is merely the latest iteration in a series of technological advances that realign the division of labor between man and machine. This trend also holds for cybersecurity, which has a history of relying on automation to process “[overwhelming amounts of information](https://link.springer.com/chapter/10.1007/978-3-031-15030-2_4).” There will still be a need for security engineers and analysts to collaborate with AI applications to defend networks and infrastructure.  

### AI Will Be Used for Evil and Good
AI will increase attack frequency. The [European Union (EU) Agency for Cybersecurity](https://www.enisa.europa.eu/sites/default/files/publications/ENISA Threat Landscape 2023.pdf) reports that attacks are increasing as bad actors leverage AI to automate data collection and identify potential targets. The [United Kingdom’s National Cyber Security Centre (NCSC)](https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat) assesses that AI will lower the barrier to entry, thereby enabling less-technical actors to participate. 

AI will increase attack efficacy. In January 2024, [the NCSC speculated](https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat) that AI could facilitate development of new exploits. Four months later, Palo Alto Networks Unit 42 researchers did exactly that. In a proof-of-concept exercise, the team used AI to compose sophisticated, polymorphic malware. They prompted their AI model to generate malware that incorporated MITRE ATT&CK techniques. 

AI will impact cybersecurity by increasing “[the effectiveness of cyber scams](https://www.europarl.europa.eu/RegData/etudes/BRIE/2024/760356/EPRS_BRI(2024)760356_EN.pdf).” AI excels at creating natural language, and criminals rely on those capabilities to compose more fluent emails and texts. In the past, poor syntax and spelling errors tipped off potential victims to the scam, but improved translations eliminated those tells. 

Finally, AI will open new attack vectors. [Criminals are incorporating AI’s ability](https://www.euronews.com/next/2023/03/25/audio-deepfake-scams-criminals-are-using-ai-to-sound-like-family-and-people-are-falling-fo) to clone someone’s voice into their scams. In 2019, [fraudsters used AI to clone the voice of a German chief executive](https://www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402) officer. Using that deep fake audio ruse, they tricked a British subordinate to wire €220,000 to them. Yet deep fake audio extends beyond simple scams, for social engineering is often used to gain initial access to a network. “[Many complex and intricate cyberattacks](https://ieeexplore.ieee.org/document/10466545) start by exploiting human users to access the organization’s system.” AI voice cloning may lead to large-scale compromises of enterprise’s IT infrastructure. 

But all is not hopeless. As [the Estonian Information System Authority](https://www.ria.ee/sites/default/files/documents/2024-02/Cyber-security-in-Estonia-2024.pdf) counseled, “AI can be also used to architect clever security solutions.” AI can be just as powerful a tool for good as it is for evil. Just as AI assists phishing attacks, it can also be used to stop them. A [Spanish company has devised a solution](https://een.ec.europa.eu/partnering-opportunities/deepfake-ai-voice-cloning-detection-against-impersonation-fraud) that detects the machine-cloned voices used in the financial scams described above. AI can also [identify phishing emails](https://ieeexplore.ieee.org/document/10466545), [deobfuscate malware scripts](https://cloud.google.com/blog/topics/threat-intelligence/gemini-malware-analysis-code-interpreter-threat-intelligence), [uncover network intrusions](https://ieeexplore.ieee.org/abstract/document/8812669), and [automate web vulnerability detection](https://unit42.paloaltonetworks.com/automated-bola-detection-and-ai/).  

### AI Impact on Cybersecurity Will Be Uneven
AI’s [impact on cybersecurity will be uneven](https://www.ncsc.gov.uk/report/impact-of-ai-on-cyber-threat). Those with better tools and better skills will be better positioned to capitalize on its potential. AI is a tool, and better tools produce better outcomes. For instance, [individuals use AI applications](https://www.theregister.com/2024/12/10/ai_slop_bug_reports) to submit “extremely low-quality, spammy, and LLM-hallucinated” bug reports to open-source software projects. These reports are low quality because they erroneously identify a vulnerability where one does not exist. In contrast, [Google engineers used AI to discover a real-world](https://googleprojectzero.blogspot.com/2024/10/from-naptime-to-big-sleep.html) vulnerability in a widely-used software. To discover the real vulnerability, the Google team created an AI agent that had been trained on previous vulnerabilities of the same software, and [they equipped their agent](https://googleprojectzero.blogspot.com/2024/06/project-naptime.html) with its own debugger and scripting environment. Armed with this training data and test setup, Google’s AI agent was better positioned to identify vulnerabilities than the general-purpose AI application that the spammy reporters likely used. 

Using AI is a skill, and better skills produce better outcomes. Recall the earlier example of Palo Alto Networks creating sophisticated malware. At the start of their project, the researchers initially failed. Only after repeated attempts did they succeed in getting their model to generate advanced malware. Engaging with AI tools requires [both prompt engineering skills](https://aws.amazon.com/what-is/prompt-engineering/) to articulate commands as well as underlying subject matter expertise to verify replies. The impact of an AI application depends in part on the skill of the human users. 

### Policy Recommendation: Develop and Recruit Talent
Policymakers should cultivate a skilled workforce to harness the gains from AI. First, the EU should continue “[to develop, attract and retain](https://digital-strategy.ec.europa.eu/en/library/eus-cybersecurity-strategy-digital-decade-0) the best cybersecurity [and AI] talent and to invest in world class research and innovation.” To do that, the EU should follow the Estonian example. [Estonia has a national program](https://e-estonia.com/cybersecurity-education-in-estonia-from-kindergarten-to-nato-cyber-defence-centre/) to foster engineering skills among its people; training starts as early as kindergarten. This program produces learning materials, develops teaching curricula, and organizes cyber competitions. Estonia leverages these efforts to encourage and prepare their youth to pursue technical careers. Furthermore, as part of its education efforts, Estonian officials also identify and reach out to young hackers as part of an effort to steer them away from illegal activity to legitimate jobs.  

Second, the EU should develop talent in people with non-traditional backgrounds. In addition to the Estonian model, Europe should also support adults wishing to transition into either cybersecurity or AI careers. There are many non-technical people who have the potential and the desire to move into tech. I know because I was one. Eight years ago, I changed careers from attorney to software engineer. This was difficult because I did not have prior experience or training, but I completed my coding bootcamp and ultimately found work as an engineer at Amazon. Now I help others make the same journey. [Amazon has internal initiatives](https://www.aboutamazon.com/news/workplace/our-upskilling-2025-programs) where it helps its non-technical employees pursue technical careers. As a volunteer with those programs, I have helped former office staff and warehouse workers prepare for engineering positions. Changing careers is daunting, but those who complete Amazon’s program find success. Policymakers should adopt initiatives like this to tap into a hidden source of talent for AI and cybersecurity roles. 

Finally, the EU should recruit and retain foreign talent. [Twelve percent of the world’s top AI talent](https://macropolo.org/interactive/digital-projects/the-global-ai-talent-tracker/) work in Europe, behind the United States (42%) and China (28%). To close that gap, Europe will need to reform its laws to be more hospitable to foreign engineers and startups. “[Labour regulations](https://digital-strategy.ec.europa.eu/en/news/simplifying-europes-startup-ecosystem-key-areas-reform), lengthy visa processes, and salary structures make it harder for startups to offer the same flexibility and opportunities as their international counterpart.” Another way to recruit foreign talent is by supporting graduate education programs at European universities. [Studies show that AI talent](https://www.technologyreview.com/2024/03/27/1090182/ai-talent-global-china-us/) tend to remain in the country where they completed their graduate degree.

### Conclusion 
AI will not replace us. Rather it will increase productivity via its ability to automate tasks and process information. AI will be used for good and ill in the world of cybersecurity. Those with better tools and more proficient at using them will wield the greatest impact. To realize the gains from AI innovation, policymakers should develop a talented workforce. This includes fostering technical skills in schools, offering avenues for adults wishing to transition into tech fields, and recruiting top talent from abroad.  

